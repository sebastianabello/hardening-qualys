# Elasticsearch Configuration
ES_BASE_URL=
ES_API_KEY=
ES_INDEX_CONTROL=qualys-control-stats
ES_INDEX_RESULTS=qualys-results

# Output Configuration
OUTPUT_BASE_DIR=./data

# Performance Settings (OPTIMIZED - Ultra-fast for large files)
WORKER_PROCESSES=4              # Number of CPU cores to use for parallel processing
CSV_PART_MAX_ROWS=1000000       # Rows per CSV file partition (lower = more files, faster ingestion)
CSV_GZIP=false                  # Enable GZIP compression (slower but smaller files)
WRITE_BUFFER_SIZE=262144        # Write buffer size in bytes (256KB default, higher = faster)
ENABLE_PARALLEL_COMPRESSION=true # Use pigz for parallel compression (requires pigz installed)
USE_PYARROW=true                # Use PyArrow for ultra-fast CSV parsing (5-10x speedup)
PYARROW_BATCH_SIZE=50000        # Rows per batch in PyArrow processing

# CORS Settings
CORS_ALLOW_ALL=true
ALLOWED_ORIGINS=[]
